{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Artorias1469/Neural_networks_1/blob/main/%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D1%81%D0%BB%D0%BE%D0%B9_(Dense)_%D0%94%D0%97_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qXycKuUA51"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMmCXubUHEb"
      },
      "source": [
        "Самостоятельно напишите нейронную сеть, которая может стать составной частью системы бота для игры в \"Крестики-нолики\". Используя подготовленную базу изображений, создайте и обучите нейронную сеть, распознающую две категории изображений: крестики и нолики. Добейтесь точности распознавания более 95% (accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvOL2h3EdC9y"
      },
      "source": [
        "# Подключение класса для создания нейронной сети прямого распространения\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Подключение класса для создания полносвязного слоя\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Подключение оптимизатора\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Подключение утилит для to_categorical\n",
        "from tensorflow.keras import utils\n",
        "# Подключение библиотеки для загрузки изображений\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Подключение библиотеки для работы с массивами\n",
        "import numpy as np\n",
        "# Подключение модуля для работы с файлами\n",
        "import os\n",
        "# Подключение библиотек для отрисовки изображений\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "# Вывод изображения в ноутбуке, а не в консоли или файле\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJSH41rM12IE",
        "outputId": "62f89768-fe1a-4cf3-eee6-60cc9c9fb15f"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "import gdown\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hw_pro.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAhCsCJ1_hJ"
      },
      "source": [
        "# Распаковываем архив hw_light.zip в папку hw_light\n",
        "!unzip -q hw_pro.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHbCet01zmG",
        "outputId": "fdeac941-7497-40f5-8919-8993512d35de"
      },
      "source": [
        "# Путь к директории с базой\n",
        "base_dir = '/content/hw_pro'\n",
        "# Создание пустого списка для загрузки изображений обучающей выборки\n",
        "x_train = []\n",
        "# Создание списка для меток классов\n",
        "y_train = []\n",
        "# Задание высоты и ширины загружаемых изображений\n",
        "img_height = 20\n",
        "img_width = 20\n",
        "# Перебор папок в директории базы\n",
        "for patch in os.listdir(base_dir):\n",
        "    # Перебор файлов в папках\n",
        "    for img in os.listdir(base_dir + '/' + patch):\n",
        "        # Добавление в список изображений текущей картинки\n",
        "        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,\n",
        "                                                         target_size=(img_height, img_width),\n",
        "                                                         color_mode='grayscale')))\n",
        "        # Добавление в массив меток, соответствующих классам\n",
        "        if patch == '0':\n",
        "            y_train.append(0)\n",
        "        else:\n",
        "            y_train.append(1)\n",
        "# Преобразование в numpy-массив загруженных изображений и меток классов\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "# Вывод размерностей\n",
        "print('Размер массива x_train', x_train.shape)\n",
        "print('Размер массива y_train', y_train.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер массива x_train (102, 20, 20, 1)\n",
            "Размер массива y_train (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJLh3F3N2DCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b81a76-92b0-4d46-c07b-6d9fa72c217d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "y_train = to_categorical(y_train, 2)\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(20, 20, 1)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "accuracy = history.history['accuracy'][-1]\n",
        "print(f'Final Accuracy: {accuracy:.4f}')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 0.5566 - loss: 0.6657\n",
            "Epoch 2/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5204 - loss: 0.6762 \n",
            "Epoch 3/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7705 - loss: 0.5032 \n",
            "Epoch 4/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.4033 \n",
            "Epoch 5/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9303 - loss: 0.3516 \n",
            "Epoch 6/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8837 - loss: 0.3194 \n",
            "Epoch 7/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8991 - loss: 0.2945 \n",
            "Epoch 8/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8474 - loss: 0.3211 \n",
            "Epoch 9/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9210 - loss: 0.2185 \n",
            "Epoch 10/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.1689 \n",
            "Epoch 11/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1079 \n",
            "Epoch 12/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1005 \n",
            "Epoch 13/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0881 \n",
            "Epoch 14/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0688 \n",
            "Epoch 15/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0619 \n",
            "Epoch 16/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0561 \n",
            "Epoch 17/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0444 \n",
            "Epoch 18/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0413 \n",
            "Epoch 19/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0406\n",
            "Epoch 20/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0341\n",
            "Final Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}